---
title: "Practical Machine Learning Project Assignment"
output: html_document
---
# 1. Cleaning data

```{r message=FALSE, warning=FALSE}
library(caret)
library(rattle)
```


```{r}
builddat=read.csv("C:/Users/Thai Thanh/Documents/Data_Analysis/8 Practical Machine Learning/data/pml-training.csv",header = T,row.names = 1)
validation=read.csv("C:/Users/Thai Thanh/Documents/Data_Analysis/8 Practical Machine Learning/data/pml-testing.csv",header = T,row.names = 1)
```

```{r}
set.seed(123)
inTrain=createDataPartition(y=builddat$classe,p=0.7,list = F)
traindat=builddat[inTrain,]
testdat=builddat[-inTrain,]
dim(traindat)
dim(testdat)
```


```{r}
# Remove zero covariates
nsv=nearZeroVar(traindat,saveMetrics = T)
traindat=traindat[,!nsv$nzv]
testdat=testdat[,!nsv$nzv]
dim(traindat)
dim(testdat)
```

```{r}
# Remove variables that are mostly NA
findNA=apply(traindat,2,function(x) (mean(is.na(x))>0.95))
traindat=traindat[,!findNA]
testdat=testdat[,!findNA]
dim(traindat)
dim(testdat)
```

```{r}
#remove unrelated variables
traindat=traindat[,-(1:4)]
testdat=testdat[,-(1:4)]
dim(traindat)
dim(testdat)
```

# 2. Prediction Model Building

## Decision Tree

```{r}
set.seed(123)
# Fit model
treeFit=train(classe~.,data=traindat,method="rpart")
fancyRpartPlot(treeFit$finalModel)
# Prediction on test data set
treePred=predict(treeFit,newdata = testdat)
# Compute out of sample accuracy
confusionMatrix(treePred,testdat$classe)
```

## Random Forest

```{r}
set.seed(123)
# Using 3-fold cross validation method to choose number of variables used at each split
# Then using the chosen number of variables to fit final model
rfControl=trainControl(method="cv", number=3,
                       verboseIter=FALSE)
rfFit=train(classe~.,data=traindat,method="rf",
            trControl=rfControl)
rfFit
rfFit$finalModel # out of sample error already computed here (OOB estimate of  error rate)
# Prediction on test data set
rfPred=predict(rfFit,testdat)
# Compute out of sample accuracy (to compare with other models)
confusionMatrix(rfPred,testdat$classe)
```

## Boosting

```{r}
set.seed(123)
# Use 5-fold cross validation method to choose interaction depth and number of trees 
# Then using the chosen interaction depth and number of trees to fit final model
boostControl=trainControl(method = "cv", number = 5)
boostFit=train(classe~.,data=traindat,method="gbm",
               trControl=boostControl,verbose=F)
boostFit
boostFit$finalModel
# Prediction on test data set
boostPred=predict(boostFit,testdat)
# Compute out of sample accuracy
confusionMatrix(boostPred,testdat$classe)
```

# 3. Select Model

We see that the Random Forest model have the highest accuracy, so we use Random Forest to predict the test dataset.

```{r}
testPred=predict(rfFit,validation)
testPred
```




